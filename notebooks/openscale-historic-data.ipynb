{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Watson Machine Learning - Load Historica data to emulate a production system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [1.0 Install Python Packages](#setup)\n",
    "- [2.0 Configure Credentials](#credentials)\n",
    "- [3.0 OpenScale configuration](#openscale)\n",
    "- [4.0 Get Subscriptions](#subscription)\n",
    "- [5.0 Historical Data](#historical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Install Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/spark/shared/user-libs/python3.6*\n",
    "\n",
    "!pip install --upgrade ibm-ai-openscale==2.2.1 --no-cache | tail -n 1\n",
    "!pip install --upgrade watson-machine-learning-client-V4==1.0.110 | tail -n 1\n",
    "!pip install --upgrade pyspark==2.3 | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action: restart the kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Configure credentials <a name=\"credentials\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Replace the `username` and `password` values of `************` with your Cloud Pak for Data `username` and `password`. The value for `url` should match the `url` for your Cloud Pak for Data cluster, which you can get from the browser address bar (be sure to include the 'https://'.</font> The credentials should look something like this (these are example values, not the ones you will use):\n",
    "\n",
    "`\n",
    "WOS_CREDENTIALS = {\n",
    "                   \"url\": \"https://zen.clusterid.us-south.containers.appdomain.cloud\",\n",
    "                   \"username\": \"cp4duser\",\n",
    "                   \"password\" : \"cp4dpass\"\n",
    "                  }\n",
    "`\n",
    "#### NOTE: Make sure that there is no trailing forward slash `/` in the `url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"************\",\n",
    "    \"username\": \"************\",\n",
    "    \"password\": \"************\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = WOS_CREDENTIALS.copy()\n",
    "WML_CREDENTIALS['instance_id']='openshift'\n",
    "WML_CREDENTIALS['version']='3.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r MODEL_NAME\n",
    "%store -r DEPLOYMENT_NAME\n",
    "%store -r DEFAULT_SPACE\n",
    "%store -r model_uid\n",
    "%store -r binding_uid\n",
    "%store -r deployment_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Configure OpenScale <a name=\"openscale\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook will now import the necessary libraries and configure OpenScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "import json\n",
    "\n",
    "wml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale import APIClient4ICP\n",
    "from ibm_ai_openscale.engines import *\n",
    "from ibm_ai_openscale.utils import *\n",
    "from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n",
    "from ibm_ai_openscale.supporting_classes.enums import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client = APIClient4ICP(WOS_CREDENTIALS)\n",
    "ai_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Get Subscription <a name=\"subscription\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription = None\n",
    "\n",
    "if subscription is None:\n",
    "    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "    for sub in subscriptions_uids:\n",
    "        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n",
    "            print(\"Found existing subscription.\")\n",
    "            subscription = ai_client.data_mart.subscriptions.get(sub)\n",
    "            subscription_uid = sub\n",
    "            print(\"subscription_uid: \" + sub)\n",
    "if subscription is None:\n",
    "    print(\"No subscription found. Please run openscale-initial-setup.ipynb to configure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Deployment UID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_client.set.default_space(DEFAULT_SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_deployments = wml_client.deployments.get_details()\n",
    "deployment_uid = None\n",
    "for deployment in wml_deployments['resources']:\n",
    "    print(deployment['entity']['name'])\n",
    "    if DEPLOYMENT_NAME == deployment['entity']['name']:\n",
    "        deployment_uid = deployment['metadata']['guid']\n",
    "        break\n",
    "        \n",
    "print(deployment_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_uid = None\n",
    "\n",
    "binding_uid = ai_client.data_mart.bindings.get_details()['service_bindings'][0]['metadata']['guid']\n",
    "if binding_uid is None:\n",
    "    print(\"Adding binding:\")\n",
    "    binding_uid = ai_client.data_mart.bindings.add('WML instance', WatsonMachineLearningInstance4ICP(wml_credentials=WML_CREDENTIALS))\n",
    "    bindings_details = ai_client.data_mart.bindings.get_details()\n",
    "else:\n",
    "    print(\"Found binding:\")\n",
    "binding_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_models = wml_client.repository.get_model_details()\n",
    "model_uid = None\n",
    "\n",
    "for model_in in wml_models['resources']:\n",
    "    if MODEL_NAME == model_in['entity']['name']:\n",
    "        model_uid = model_in['metadata']['guid']\n",
    "        break\n",
    "        \n",
    "print(model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Historical data <a name=\"historical\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8.1 Insert historical payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section of the notebook downloads and writes historical data to the payload and measurement tables to simulate a production model that has been monitored and receiving regular traffic for the last seven days. This historical data can be viewed in the Watson OpenScale user interface. The code uses the Python and REST APIs to write this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm history_payloads_with_transaction_*.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/fastpath/history_payloads_with_transaction_id_0.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/fastpath/history_payloads_with_transaction_id_1.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/fastpath/history_payloads_with_transaction_id_2.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/fastpath/history_payloads_with_transaction_id_3.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/fastpath/history_payloads_with_transaction_id_4.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/fastpath/history_payloads_with_transaction_id_5.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/fastpath/history_payloads_with_transaction_id_6.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale.utils.inject_demo_data import DemoData\n",
    "import os\n",
    "\n",
    "historicalData = DemoData(WOS_CREDENTIALS, ai_client)\n",
    "historical_data_path=os.getcwd()\n",
    "\n",
    "historicalData.load_historical_scoring_payload(subscription, deployment_uid,file_path=historical_data_path, day_template=\"history_payloads_with_transaction_id_{}.json\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_mart_id = subscription.get_details()['metadata']['url'].split('/service_bindings')[0].split('marts/')[1]\n",
    "print(data_mart_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "performance_metrics_url = WOS_CREDENTIALS['url'] + subscription.get_details()['metadata']['url'].split('/service_bindings')[0] + '/metrics'\n",
    "print(performance_metrics_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Insert historical fairness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm history_fairness.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/history_fairness.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "def create_token():\n",
    "    header = {\n",
    "                    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "                    \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.Session().get(\n",
    "            WOS_CREDENTIALS['url'] + '/v1/preauth/validateAuth',\n",
    "            headers=header,\n",
    "            auth=HTTPBasicAuth(\n",
    "                WOS_CREDENTIALS['username'],\n",
    "                WOS_CREDENTIALS['password']\n",
    "            ),\n",
    "            verify=False)\n",
    "\n",
    "    response = handle_response(200, 'access token', response, True)\n",
    "    token = response['accessToken']\n",
    "\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iam_token = create_token()\n",
    "iam_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % iam_token\n",
    "}\n",
    "\n",
    "with open('history_fairness.json', 'r') as history_file:\n",
    "    payloads = json.load(history_file)\n",
    "\n",
    "for day in range(historyDays):\n",
    "    print('Loading day', day + 1)\n",
    "    for hour in range(24):\n",
    "        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        index = (day * 24 + hour) % len(payloads) # wrap around and reuse values if needed\n",
    "        \n",
    "        qualityMetric = {\n",
    "            'metric_type': 'fairness',\n",
    "            'binding_id': binding_uid,\n",
    "            'timestamp': score_time,\n",
    "            'subscription_id': model_uid,\n",
    "            'asset_revision': model_uid,\n",
    "            'deployment_id': deployment_uid,\n",
    "            'value': payloads[index]\n",
    "        }\n",
    "\n",
    "        response = requests.post(performance_metrics_url, json=[qualityMetric], headers=iam_headers, verify=False)\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Insert historical debias metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm history_debias.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/history_debias.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_token = create_token()\n",
    "iam_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % iam_token\n",
    "}\n",
    "\n",
    "with open('history_debias.json', 'r') as history_file:\n",
    "    payloads = json.load(history_file)\n",
    "\n",
    "for day in range(historyDays):\n",
    "    print('Loading day', day + 1)\n",
    "    for hour in range(24):\n",
    "        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        index = (day * 24 + hour) % len(payloads) # wrap around and reuse values if needed\n",
    "\n",
    "        qualityMetric = {\n",
    "            'metric_type': 'debiased_fairness',\n",
    "            'binding_id': binding_uid,\n",
    "            'timestamp': score_time,\n",
    "            'subscription_id': model_uid,\n",
    "            'asset_revision': model_uid,\n",
    "            'deployment_id': deployment_uid,\n",
    "            'value': payloads[index]\n",
    "        }\n",
    "\n",
    "        response = requests.post(performance_metrics_url, json=[qualityMetric], headers=iam_headers, verify=False)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Insert historical quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iam_token = create_token()\n",
    "iam_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % iam_token\n",
    "}\n",
    "\n",
    "measurements = [0.76, 0.78, 0.68, 0.72, 0.73, 0.77, 0.80]\n",
    "for day in range(historyDays):\n",
    "    print('Day', day + 1)\n",
    "    for hour in range(24):\n",
    "        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        qualityMetric = {\n",
    "            'metric_type': 'quality',\n",
    "            'binding_id': binding_uid,\n",
    "            'timestamp': score_time,\n",
    "            'subscription_id': model_uid,\n",
    "            'asset_revision': model_uid,\n",
    "            'deployment_id': deployment_uid,\n",
    "            'value': {\n",
    "                'quality': measurements[day],\n",
    "                'threshold': 0.7,\n",
    "                'metrics': [\n",
    "                    {\n",
    "                        'name': 'auroc',\n",
    "                        'value': measurements[day],\n",
    "                        'threshold': 0.7\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = requests.post(performance_metrics_url, json=[qualityMetric], headers=iam_headers, verify=False)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Insert historical confusion matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm history_quality_metrics.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wos/history_quality_metrics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_url = WOS_CREDENTIALS['url'] + subscription.get_details()['metadata']['url'].split('/service_bindings')[0] + '/measurements'\n",
    "print(measurements_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history_quality_metrics.json') as json_file:\n",
    "    records = json.load(json_file)\n",
    "\n",
    "for day in range(historyDays):\n",
    "    index = 0\n",
    "    measurments = []\n",
    "    print('Day', day + 1)\n",
    "    \n",
    "    for hour in range(24):\n",
    "        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "        measurement = {\n",
    "            \"monitor_definition_id\": 'quality',\n",
    "            \"binding_id\": subscription.binding_uid,\n",
    "            \"subscription_id\": subscription.uid,\n",
    "            \"asset_id\": subscription.source_uid,\n",
    "            'metrics': [records[index]['metrics']],\n",
    "            'sources': [records[index]['sources']],\n",
    "            'timestamp': score_time\n",
    "        }\n",
    "\n",
    "        measurments.append(measurement)\n",
    "        index+=1\n",
    "\n",
    "    response = requests.post(measurements_url, json=measurments, headers=ai_client._get_headers(), verify=False)\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Insert historical performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iam_token = create_token()\n",
    "iam_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % iam_token\n",
    "}\n",
    "\n",
    "for day in range(historyDays):\n",
    "    print('Day', day + 1)\n",
    "    for hour in range(24):\n",
    "        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        score_count = random.randint(60, 600)\n",
    "        score_resp = random.uniform(60, 300)\n",
    "\n",
    "        performanceMetric = {\n",
    "            'metric_type': 'performance',\n",
    "            'binding_id': binding_uid,\n",
    "            'timestamp': score_time,\n",
    "            'subscription_id': model_uid,\n",
    "            'asset_revision': model_uid,\n",
    "            'deployment_id': deployment_uid,\n",
    "            'value': {\n",
    "                'response_time': score_resp,\n",
    "                'records': score_count\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = requests.post(performance_metrics_url, json=[performanceMetric], headers=iam_headers, verify=False)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Insert historical manual labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_labeling_url = WOS_CREDENTIALS['url'] + subscription.get_details()['metadata']['url'].split('/service_bindings')[0] + '/manual_labelings'\n",
    "print(manual_labeling_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm history_manual_labeling.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/history_manual_labeling.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iam_token = create_token()\n",
    "iam_headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % iam_token\n",
    "}\n",
    "\n",
    "with open('history_manual_labeling.json', 'r') as history_file:\n",
    "    records = json.load(history_file)\n",
    "\n",
    "for day in range(historyDays):\n",
    "    print('Loading day', day + 1)\n",
    "    record_json = []\n",
    "    for hour in range(24):\n",
    "        for record in records:\n",
    "            if record['fastpath_history_day'] == day and record['fastpath_history_hour'] == hour:\n",
    "                record['binding_id'] = binding_uid\n",
    "                record['subscription_id'] = model_uid\n",
    "                record['asset_revision'] = model_uid\n",
    "                record['deployment_id'] = deployment_uid\n",
    "                record['scoring_timestamp'] = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "                record_json.append(record)\n",
    "    response = requests.post(manual_labeling_url, json=record_json, headers=iam_headers, verify=False)\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8 Additional data to help debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Datamart:', data_mart_id)\n",
    "print('Model:', model_uid)\n",
    "print('Deployment:', deployment_uid)\n",
    "print('Binding:', binding_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.9 Identify transactions for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transaction IDs identified by the cells below can be copied and pasted into the Explainability tab of the OpenScale dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "payload_data = subscription.payload_logging.get_table_content(limit=10)\n",
    "payload_data.filter(items=['scoring_id', 'predictedLabel', 'probability'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have finished the hands-on lab for IBM Watson OpenScale. You can now view the OpenScale dashboard by going to the CPD `Home` page, and clicking `Services`. Choose the `OpenScale` tile and click the menu to `Open`. Click on the tile for the model you've created to see fairness, accuracy, and performance monitors. Click on the timeseries graph to get detailed information on transactions during a specific time window.\n",
    "\n",
    "OpenScale shows model performance over time. You have two options to keep data flowing to your OpenScale graphs:\n",
    "  * Download, configure and schedule the [model feed notebook](https://raw.githubusercontent.com/emartensibm/german-credit/master/german_credit_scoring_feed.ipynb). This notebook can be set up with your WML credentials, and scheduled to provide a consistent flow of scoring requests to your model, which will appear in your OpenScale monitors.\n",
    "  * Re-run this notebook. Running this notebook from the beginning will delete and re-create the model and deployment, and re-create the historical data. Please note that the payload and measurement logs for the previous deployment will continue to be stored in your datamart, and can be deleted if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Eric Martens, is a technical specialist having expertise in analysis and description of business processes, and their translation into functional and non-functional IT requirements. He acts as the interpreter between the worlds of IT and business.\n",
    "\n",
    "Lukasz Cmielowski, PhD, is an Automation Architect and Data Scientist at IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge.\n",
    "\n",
    "Zilu (Peter) Tang, is a cognitive developer with experties in deep learning and enterprise AI solutions from Watson Openscale to many other cutting-edge IBM research projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook will train, create and deploy a Credit Risk model. It will then configure OpenScale to monitor drift in data and accuracy by injecting sample payloads for viewing in the OpenScale Insights dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [1. Setup](#setup)\n",
    "- [2. Model building and deployment](#model)\n",
    "- [3. OpenScale configuration](#openscale)\n",
    "- [4. Generate drift model](#driftmodel)\n",
    "- [5. Submit payload](#payload)\n",
    "- [6. Enable drift monitoring](#monitor)\n",
    "- [7. Run drift monitor](# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade watson-machine-learning-client-V4 | tail -n 1\n",
    "!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1\n",
    "!pip install --upgrade ibm-wos-utils |tail -n 1\n",
    "! pip install scikit-learn==0.20.2 | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action: restart the kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- WOS_CREDENTIALS\n",
    "- WML_CREDENTIALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The url for `WOS_CREDENTIALS` is the url of the CP4D cluster, i.e. `https://zen-cpd-zen.apps.com`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Replace the `username` and `password` values of `************` with your Cloud Pak for Data `username` and `password`. The value for `url` should match the `url` for your Cloud Pak for Data cluster, which you can get from the browser address bar (be sure to include the 'https://'.</font> The credentials should look something like this (these are example values, not the ones you will use):\n",
    "\n",
    "`\n",
    "wml_credentials = {\n",
    "                   \"url\": \"https://zen.clusterid.us-south.containers.appdomain.cloud\",\n",
    "                   \"username\": \"cp4duser\",\n",
    "                   \"password\" : \"cp4dpass\",\n",
    "                   \"instance_id\": \"wml_local\",\n",
    "                   \"version\" : \"3.0.0\"\n",
    "                  }\n",
    "`\n",
    "#### NOTE: Make sure that there is no trailing forward slash `/` in the `url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"************\",\n",
    "    \"username\": \"************\",\n",
    "    \"password\": \"************\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = WOS_CREDENTIALS.copy()\n",
    "WML_CREDENTIALS['instance_id']='openshift'\n",
    "WML_CREDENTIALS['version']='3.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r MODEL_NAME\n",
    "%store -r DEPLOYMENT_NAME\n",
    "%store -r DEFAULT_SPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf german_credit_data_biased_training.csv\n",
    "!wget https://raw.githubusercontent.com/scottdangelo/credit-risk-workshop-cpd/addData/data/openscale/german_credit_data_biased_training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv('german_credit_data_biased_training.csv', sep=\",\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Configure OpenScale <a name=\"openscale\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook will now import the necessary libraries and set up a Python OpenScale client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ibm_ai_openscale import APIClient4ICP\n",
    "from ibm_ai_openscale.engines import *\n",
    "from ibm_ai_openscale.utils import *\n",
    "from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n",
    "from ibm_ai_openscale.supporting_classes.enums import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "import json\n",
    "\n",
    "wml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client = APIClient4ICP(WOS_CREDENTIALS)\n",
    "ai_client.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription = None\n",
    "\n",
    "if subscription is None:\n",
    "    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "    for sub in subscriptions_uids:\n",
    "        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n",
    "            print(\"Found existing subscription.\")\n",
    "            subscription = ai_client.data_mart.subscriptions.get(sub)\n",
    "if subscription is None:\n",
    "    print(\"No subscription found. Please run openscale-initial-setup.ipynb to configure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Deployment UID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_client.set.default_space(DEFAULT_SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_deployments = wml_client.deployments.get_details()\n",
    "deployment_uid = None\n",
    "for deployment in wml_deployments['resources']:\n",
    "    print(deployment['entity']['name'])\n",
    "    if DEPLOYMENT_NAME == deployment['entity']['name']:\n",
    "        deployment_uid = deployment['metadata']['guid']\n",
    "        break\n",
    "        \n",
    "print(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Generate drift model <a name=\"driftmodel\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drift requires a trained model to be uploaded manually for WML. You can train, create and download a drift detection model using the code below. The entire code can be found in the [training_statistics_notebook](https://github.com/IBM-Watson/aios-data-distribution/blob/master/training_statistics_notebook.ipynb) ( check for Drift detection model generation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_info = {\n",
    "  \"class_label\":'Risk',\n",
    "   \"feature_columns\":[\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n",
    "    \"categorical_columns\":[\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set model_type. Acceptable values are:[\"binary\",\"multiclass\",\"regression\"]\n",
    "model_type = \"binary\"\n",
    "#model_type = \"multiclass\"\n",
    "#model_type = \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(training_data_frame):\n",
    "     \n",
    "      WML_CREDENTAILS = WML_CREDENTIALS\n",
    "      \n",
    "      \n",
    "      #The data type of the label column and prediction column should be same .\n",
    "      #User needs to make sure that label column and prediction column array should have the same unique class labels\n",
    "      prediction_column_name = \"predictedLabel\"\n",
    "      probability_column_name = \"probability\"\n",
    "        \n",
    "      feature_columns = list(training_data_frame.columns)\n",
    "      training_data_rows = training_data_frame[feature_columns].values.tolist()\n",
    "      #print(training_data_rows)\n",
    "    \n",
    "\n",
    "    \n",
    "      payload_scoring = {\n",
    "          wml_client.deployments.ScoringMetaNames.INPUT_DATA: [{\n",
    "               \"fields\": feature_columns,\n",
    "               \"values\": [x for x in training_data_rows]\n",
    "          }]\n",
    "      }\n",
    "      \n",
    "      score = wml_client.deployments.score(deployment_uid, payload_scoring)\n",
    "      score_predictions = score.get('predictions')[0]\n",
    "      \n",
    "      prob_col_index = list(score_predictions.get('fields')).index(probability_column_name)\n",
    "      predict_col_index = list(score_predictions.get('fields')).index(prediction_column_name)\n",
    "      \n",
    "      if prob_col_index < 0 or predict_col_index < 0:\n",
    "          raise Exception(\"Missing prediction/probability column in the scoring response\")\n",
    "          \n",
    "      import numpy as np\n",
    "      probability_array = np.array([value[prob_col_index] for value in score_predictions.get('values')])\n",
    "      prediction_vector = np.array([value[predict_col_index] for value in score_predictions.get('values')])\n",
    "      \n",
    "      return probability_array, prediction_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate drift detection model\n",
    "from ibm_wos_utils.drift.drift_trainer import DriftTrainer\n",
    "\n",
    "drift_detection_input = {\n",
    "        \"feature_columns\":training_data_info.get('feature_columns'),\n",
    "        \"categorical_columns\":training_data_info.get('categorical_columns'),\n",
    "        \"label_column\": training_data_info.get('class_label'),\n",
    "        \"problem_type\": model_type\n",
    "    }\n",
    "    \n",
    "    \n",
    "drift_trainer = DriftTrainer(data_df,drift_detection_input)\n",
    "if model_type != \"regression\":\n",
    "    #Note: batch_size can be customized by user as per the training data size\n",
    "    drift_trainer.generate_drift_detection_model(score,batch_size=data_df.shape[0])\n",
    "    \n",
    "    #Note: Two column constraints are not computed beyond two_column_learner_limit(default set to 200)\n",
    "    #User can adjust the value depending on the requirement\n",
    "drift_trainer.learn_constraints(two_column_learner_limit=200)\n",
    "drift_trainer.create_archive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a download link for drift detection model\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "import io\n",
    "\n",
    "def create_download_link_for_ddm( title = \"Download Drift detection model\", filename = \"drift_detection_model.tar.gz\"):  \n",
    "    \n",
    "    #Retains stats information    \n",
    "\n",
    "    with open(filename,'rb') as file:\n",
    "        ddm = file.read()\n",
    "    b64 = base64.b64encode(ddm)\n",
    "    payload = b64.decode()\n",
    "        \n",
    "    html = '<a download=\"{filename}\" href=\"data:text/json;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "    \n",
    "create_download_link_for_ddm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Submit payload <a name=\"payload\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the model so we can configure monitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the WML service has been bound and the subscription has been created, we need to send a request to the model before we configure OpenScale. This allows OpenScale to create a payload log in the datamart with the correct schema, so it can capture data coming into and out of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n",
    "values = [\n",
    "  [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n",
    "  [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n",
    "]\n",
    "\n",
    "payload_scoring = {\"fields\": fields,\"values\": values}\n",
    "payload = {\n",
    "    wml_client.deployments.ScoringMetaNames.INPUT_DATA: [payload_scoring]\n",
    "}\n",
    "scoring_response = wml_client.deployments.score(deployment_uid, payload)\n",
    "\n",
    "\n",
    "\n",
    "print('Single record scoring result:', '\\n fields:', scoring_response['predictions'][0]['fields'], '\\n values: ', scoring_response['predictions'][0]['values'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Enable drift monitoring <a name=\"monitor\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.drift_monitoring.enable(threshold=0.05, min_records=10,model_path=\"./drift_detection_model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Run Drift monitor on demand <a name=\"driftrun\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm german_credit_feed.json\n",
    "!wget https://raw.githubusercontent.com/IBM/cpd-intelligent-loan-agent-assets/master/data/german_credit_feed.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open('german_credit_feed.json', 'r') as scoring_file:\n",
    "    scoring_data = json.load(scoring_file)\n",
    "\n",
    "fields = scoring_data['fields']\n",
    "values = []\n",
    "for _ in range(10):\n",
    "    current = random.choice(scoring_data['values'])\n",
    "    #set age of all rows to 100 to increase drift values on dashboard\n",
    "    current[12] = 100\n",
    "   \n",
    "    values.append(current)\n",
    "payload_scoring = {\"fields\": fields, \"values\": values}\n",
    "payload = {\n",
    "    wml_client.deployments.ScoringMetaNames.INPUT_DATA: [payload_scoring]\n",
    "}\n",
    "scoring_response = wml_client.deployments.score(deployment_uid, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_run_details = subscription.drift_monitoring.run(background_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.drift_monitoring.get_table_content()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have finished running all the cells within the notebook for IBM Watson OpenScale. You can now view the OpenScale dashboard by going to the CP4D `Home` page, and clicking `Services`. Choose the `OpenScale` tile and click the menu to `Open`. Click on the tile for the model you've created to see fairness, accuracy, and performance monitors. Click on the timeseries graph to get detailed information on transactions during a specific time window.\n",
    "\n",
    "OpenScale shows model performance over time. You have two options to keep data flowing to your OpenScale graphs:\n",
    "  * Download, configure and schedule the [model feed notebook](https://raw.githubusercontent.com/emartensibm/german-credit/master/german_credit_scoring_feed.ipynb). This notebook can be set up with your WML credentials, and scheduled to provide a consistent flow of scoring requests to your model, which will appear in your OpenScale monitors.\n",
    "  * Re-run this notebook. Running this notebook from the beginning will delete and re-create the model and deployment, and re-create the historical data. Please note that the payload and measurement logs for the previous deployment will continue to be stored in your datamart, and can be deleted if necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
